## Tiny ImageNet-200
Tiny ImageNet-200 是一个用于计算机视觉研究的图像数据集，它是著名的 ImageNet 数据集的一个小型版本。这个数据集旨在提供一个更小、更易于管理的数据集，同时保持 ImageNet 的多样性和挑战性。以下是 Tiny ImageNet-200 的一些主要特点：
1. **图像数量和尺寸**：Tiny ImageNet-200 包含 200 个类别，每个类别有 500 张训练图像、50 张验证图像和 50 张测试图像。每张图像的分辨率为 64x64 像素，这比原始 ImageNet 中的图像小得多。
2. **类别**：这些类别是从原始 ImageNet 数据集中选取的，涵盖了各种物体、动物和场景。
3. **使用场景**：由于其相对较小的规模，Tiny ImageNet-200 通常用于教学、快速原型制作和实验，尤其是在计算资源有限的情况下。
4. **文件结构**：数据集通常包含三个主要部分：训练集、验证集和测试集。每部分都有相应的图像文件和标注文件（标注文件在测试集中可能不可用）。
5. **挑战性**：尽管 Tiny ImageNet-200 的规模较小，但它依然提供了图像分类、对象识别等任务的挑战性。对于初学者和中级研究人员来说，它是一个很好的入门级数据集。
6. **教育用途**：由于其规模和复杂性适中，Tiny ImageNet-200 经常被用于学术课程和在线课程，用于教授深度学习和计算机视觉的基本概念。
7. **性能基准**：它也被用作评估和比较不同机器学习模型性能的基准。
总之，Tiny ImageNet-200 是一个非常实用的数据集，用于在资源有限的环境中测试和开发计算机视觉模型，同时提供足够的挑战性来模拟更大、更复杂的数据集。

在`RawData`中，一共有200个类别，在训练集`train`中，是按照类别创建的文件夹，每个类别文件夹下有500张这个类别的图片，可以读取文件夹下的`_box.txt`文件来获得类别下的图片名称。对于验证集，则是将所有的验证集图片放在了`val`文件夹下，可以读取文件夹下`val_annotations.txt`，获取每个图片对应什么类别，每个类别下，有五十张`val`图片。
## TOP1—ACC
"Top-1 Accuracy"（ACC）是一种在机器学习和统计分类中常用的性能度量指标。这种度量方法主要用于评估==分类模型==的性能，尤其是在有多个类别的情况下。具体来说，它指的是：
1. **定义**：Top-1 准确率是指模型预测的最可能的类别（即置信度最高的类别）是正确的比例。换句话说，它衡量了模型在所有测试样本中有多少比例是准确地预测了其真实标签。
2. **计算方法**：计算 Top-1 准确率的方法是将正确预测的样本数除以总样本数。公式可以表示为：$$\text{Top-1 Accuracy} = \frac{\text{正确预测的样本数}}{\text{总样本数}}$$
3. **应用场景**：这种度量方法广泛应用于各种分类任务中，如图像识别、语音识别、文本分类等。
4. **局限性**：虽然 Top-1 准确率是一个直观且常用的性能指标，但它并不总是提供完整的性能画面。在一些情况下，可能还需要考虑其他指标，如精确度、召回率、F1 分数等，特别是在类别不平衡的情况下。
总的来说，Top-1 准确率提供了一个快速且直观的方式来评估分类模型在预测最可能类别方面的效能。

## 目的
要调整dropout、normalization、learning rate decay、residual connections和网络深度，你需要执行一系列的步骤，涉及对网络架构和训练配置的修改。下面是针对每个元素的具体建议：
### 1. Dropout
- **代码更改**：在网络的适当层中添加或修改dropout层。例如，在PyTorch中，你可以使用`torch.nn.Dropout(p=0.5)`来实现dropout，其中`p`是dropout的概率。
- **实验调整**：你需要实验不同的dropout率（例如0.2、0.3、0.5等），以找到最优的设置。通常，在较大或过拟合的网络中使用更高的dropout率。
### 2. Normalization
- **代码更改**：如果你的网络使用批量归一化（如`BatchNorm2d`），你可以考虑使用其他类型的归一化技术，如层归一化、组归一化等。
- **实验调整**：不同的归一化技术可能在不同的网络架构和数据集上有不同的表现。实验以确定哪种归一化最适合你的网络。
### 3. Learning Rate Decay
- **代码更改**：选择合适的学习率衰减策略，如阶梯衰减、指数衰减或余弦退火，并在训练循环中实现它。
- **实验调整**：调整衰减策略的参数，如衰减因子、步长等，以找到最优化性能的设置。
### 4. Residual Connections
- **代码更改**：在网络中添加或修改残差连接。这通常意味着将网络的输入添加到其输出（例如，在卷积层之后）。
- **实验调整**：在不同层或块中实验残差连接，以观察它们对性能的影响。在更深的网络中，残差连接特别有用。
### 5. Network Depth
- **代码更改**：增加或减少网络中的层数（例如，添加或移除卷积层、全连接层等）。
- **实验调整**：调整网络深度并评估其对性能的影响。更深的网络可能需要更复杂的优化策略，如更小的学习率、更长的训练时间等。
### 综合考虑
- **性能监测**：在进行这些调整时，密切监控模型的性能，包括训练和验证损失、准确率等指标。
- **超参数调优**：使用网格搜索、随机搜索或贝叶斯优化等方法进行超参数调优，以找到最佳的参数组合。
- **交叉验证**：使用交叉验证来确保你的调整在不同的数据划分上都是稳健的。
这些调整通常需要进行大量的实验和迭代，因为不同的数据集和任务可能需要不同的配置。务必保持记录和比较不同配置的性能，以便找到最适合你的特定问题的解决方案。
## Result
使用 MultiStepLR
```python
from torch.optim.lr_scheduler import MultiStepLR
 if lrd:
            self.schedule = MultiStepLR(self.optimizer, milestones=[10,15,20,25,30,35,40,45,50,55,60,65,70,75,80], gamma=0.1)
```