---
creationDate: 2023-10-16 22:58
card_type: 数学知识
---
**交叉熵 (Cross Entropy)** 是衡量两个概率分布之间的不相似度的一个度量。它经常在机器学习中用于分类问题，特别是在逻辑回归和深度学习中。
给定两个概率分布$P$和$Q$，交叉熵定义为：
$$H(P, Q) = -\sum_{i} P(i) \log Q(i)$$
其中，$P(i)$ 是真实分布 $P$ 在事件 $i$ 上的概率，而 $Q(i)$ 是模型预测的分布 $Q$ 在事件 $i$ 上的概率。
几点需要注意的是：
1. 交叉熵是用来衡量模型预测的分布 $Q$ 与真实分布 $P$ 之间的不相似度。值越小，表示模型的预测越接近真实分布。
2. 在机器学习中，我们经常试图最小化交叉熵损失函数，以此来训练模型。
3. 交叉熵与KL散度有关。实际上，交叉熵可以被分解为真实分布的熵和两个分布之间的KL散度：$$H(P, Q) = H(P) + D_{KL}(P || Q)$$ 其中 $H(P)$ 是 $P$ 的熵。

