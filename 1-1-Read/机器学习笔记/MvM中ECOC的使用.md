
[[距离函数]] #机器学习笔记

----

让我们通过一个具体的例子来说明ECOC（Error-Correcting Output Codes）在多分类问题中的应用：
假设我们有一个简单的动物分类问题，其中有4个类别：猫、狗、鸟、鱼。
### 步骤1：类别划分
我们决定创建3个不同的二分类划分（$M = 3$），如下所示：
- 划分1：哺乳动物 vs. 非哺乳动物（猫、狗 vs. 鸟、鱼）
- 划分2：陆地动物 vs. 水生动物（猫、狗、鸟 vs. 鱼）
- 划分3：宠物 vs. 非宠物（猫、狗 vs. 鸟、鱼）（假设鸟、鱼不是宠物）
### 步骤2：生成编码矩阵
根据上述划分，我们为每个类别创建编码：
- 猫：[1, 1, 1] （在所有划分中都是正类）
- 狗：[1, 1, 1] （在所有划分中都是正类）
- 鸟：[0, 0, 0] （在所有划分中都是负类）
- 鱼：[0, 1, 0] （只在第二划分中是正类）
编码矩阵如下：
```
猫：1  1  1
狗：1  1  1
鸟：0  0  0
鱼：0  1  0
```
### 步骤3：训练二分类器
对于每个划分，我们从数据集中提取对应的二分类训练集，并训练一个二分类器：
- 分类器1：区分哺乳动物和非哺乳动物。
- 分类器2：区分陆地动物和水生动物。
- 分类器3：区分宠物和非宠物。
### 步骤4：多分类预测
现在，假设我们有一个新的观测样本，我们不知道它属于哪个类别。我们将这个样本通过所有三个分类器进行预测，得到一个三位编码。
假设这个新样本通过三个分类器的预测编码是 [1, 0, 1]。
### 步骤5：解码与分类决策
最后，我们将这个预测编码与我们的编码矩阵中的行进行比较，寻找汉明距离最小的类别。在这个例子中，预测编码与猫和狗的编码距离最近（汉明距离为1），与鸟和鱼的编码距离更远（汉明距离为2或3）。
因此，根据ECOC的解码规则，我们将新样本归类为猫或狗。如果需要进一步区分，可能需要额外的信息或分类规则。
这个例子简化了实际中的ECOC应用，实际应用可能涉及更复杂的编码方案和更大的数据集，但基本的概念和流程是一致的。