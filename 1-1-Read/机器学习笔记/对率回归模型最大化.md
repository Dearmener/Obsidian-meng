
 [[极大似然估计]] #机器学习笔记
 
-----
![[Pasted image 20231226150814.png]]
这个方程是逻辑回归中的对数似然函数（log-likelihood function）的表示。这个函数被用来估计模型参数 $w$ 和 $b$，其中：
- $\ell(w, b)$ 表示对数似然函数。
- $m$ 是数据集中观测值的数量。
- $p(y_i | x_i; w, b)$ 是给定参数 $w$（权重向量）和 $b$（偏置或截距项）以及特征向量 $x_i$ 时，观测到 $y_i$ 的概率。

- $\ln$ 表示自然对数。

在逻辑回归中，$p(y_i | x_i; w, b)$ 通常表示为：

$$p(y_i | x_i; w, b) = \frac{1}{1 + e^{-(w^T x_i + b)}}$$

这是一个sigmoid函数，它给出了给定特征 $x_i$ 下，目标变量 $y_i$ 为1的概率。逻辑回归的目标是找到参数 $w$ 和 $b$ 的值，使得对数似然函数最大化，这反映了实际观测数据在当前模型下出现的概率最大。

在进行极大似然估计时，通常通过梯度上升（或者对于最小化问题的梯度下降）算法来找到最大化对数似然函数的参数。这个过程包括计算对数似然函数关于 $w$ 和 $b$ 的偏导数，然后迭代地更新这些参数，直到找到函数的最大值。

## 形式一
方程是逻辑回归中对数似然函数的一般形式，它描述了模型参数 $w$ 和 $b$ 关于数据集的对数似然。这里 $p(y_i | x_i; w, b)$ 是在参数 $w$ 和 $b$ 给定的情况下，数据点 $(x_i, y_i)$ 按照逻辑回归模型的分布假设所计算出的概率。
具体来说，这个方程是如何得来的：
1. 逻辑回归模型使用Sigmoid函数来预测给定输入 $x_i$ 下目标变量 $y_i$ 为1的概率：
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$
这里 $z = w^T x_i + b$，其中 $w^T x_i$ 是权重向量 $w$ 和特征向量 $x_i$ 的点积，$b$ 是偏置项。
2. 对于二分类问题，目标变量 $y_i$ 只能取0或1。逻辑回归模型预测的概率为：
$$p(y_i | x_i; w, b) = \sigma(w^T x_i + b)^{y_i}(1 - \sigma(w^T x_i + b))^{1 - y_i}$$
3. 似然函数 $L(w, b)$ 是所有观测数据在模型中的联合概率，由于观测独立，它是各个观测概率的乘积：
$$L(w, b) = \prod_{i=1}^{m} p(y_i | x_i; w, b)$$
4. 对数似然函数 $\ell(w, b)$ 是似然函数的对数，通常是为了计算方便，因为乘积的对数可以转化为求和：
$$\ell(w, b) = \sum_{i=1}^{m} \ln p(y_i | x_i; w, b)$$
5. 在逻辑回归中，我们通过找到 $w$ 和 $b$ 的值来最大化对数似然函数，这相当于找到了使观测数据出现概率最大的模型参数。
在实际应用中，通常使用梯度上升或梯度下降等数值优化方法来求解这个最大化问题，因为对数似然函数通常没有解析解。通过最大化这个对数似然函数，我们能够估计出模型的参数 $w$ 和 $b$，这样的参数可以使得模型对观测数据的预测概率最大。

## 形式二
这个方程是在逻辑回归模型中通过极大似然估计法（Maximum Likelihood Estimation, MLE）推导出的对数似然函数。逻辑回归是一种用于二分类问题的统计模型，它预测的是一个结果为0或1的概率。以下是这个方程推导的步骤：
1. **模型设定**：在逻辑回归中，输出 $y$ 被假设为一个二项分布，其中 $p(y_i=1 | x_i; w, b)$ 由sigmoid函数给出，即：
$$p(y_i=1 | x_i; w, b) = \frac{1}{1 + e^{-(w^T x_i + b)}}$$
同样地，$p(y_i=0 | x_i; w, b)$ 就是 1 减去这个概率：
$$p(y_i=0 | x_i; w, b) = 1 - \frac{1}{1 + e^{-(w^T x_i + b)}}$$
2. **似然函数**：似然函数 $L(w, b)$ 是在给定参数 $w$ 和 $b$ 时，观察到数据集 $\{(x_1, y_1), ..., (x_m, y_m)\}$ 的概率。因为观测值是独立的，所以这个概率是每个观测概率的乘积：
$$L(w, b) = \prod_{i=1}^{m} p(y_i | x_i; w, b)^{y_i} (1 - p(y_i | x_i; w, b))^{1 - y_i}$$
3. **对数似然函数**：对数似然函数 $\ell(w, b)$ 是似然函数的对数，通常使用自然对数：
$$\ell(w, b) = \ln L(w, b) = \sum_{i=1}^{m} [y_i \ln p(y_i | x_i; w, b) + (1 - y_i) \ln (1 - p(y_i | x_i; w, b))]$$
4. **最大化对数似然函数**：通过对 $\ell(w, b)$ 关于 $w$ 和 $b$ 进行求导，并设置导数为0，可以得到参数的最优估计值。通常，这需要使用数值优化方法，比如梯度上升或牛顿-拉夫森法，因为这个方程式没有闭式解。
在推导过程中，对数似然函数是用来捕获模型在所有可能的 $w$ 和 $b$ 值下，使观测数据出现概率最大化的参数。通过最大化对数似然函数，我们能找到最佳拟合数据的模型参数。