
## 张量
```python
import torch
x = torch.arange(12) #生成从0-11的一维向量
x.shape #x的大小
x.reshape(3,4)#将上面的0-11的一维向量转化为3*4的矩阵
```

```python
X = torch.arange(12,dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[1,2,3,1],[4,5,6,4],[7,8,9,9]]).type(torch.float32) #使用tensor生成张量
```


## 连结 concatenate
创建两个三维的张量，并且使用`CAT`将他们拼接起来
```python
X_1 = torch.arange(36).reshape((3,3,4))
X_2 = torch.arange(36,72).reshape((3,3,4))
```
![[Pasted image 20231106120607.png|250]]
```python
torch.cat((X_1,X_2),dim=0)：使用cat，拼接维度。
```


![[Pasted image 20231106120656.png|250]] ![[Pasted image 20231106120717.png|300]]

```python
torch.cat((X_1,X_2),dim=1) #拼接行，使行数变多
```
![[Pasted image 20231106121418.png|375]]
## 广播机制
对于不同形状的张量，一个三行一列，一个一行两列，如果两个相加，则复制到与对方列数或行书相同的情况下再相加
```python
a = torch.arange(3).reshape(3,1)
b = torch.arange(3,5).reshape(1,2)
a+b
```
结果：![[Pasted image 20231106152546.png|216]]
张量a扩展到三行两列，张量b扩展到三行两列。

**广播的基本原则：**
- 这两个维度的大小相等。
- 某个维度 一个张量有，一个张量没有。
- 某个维度 一个张量有，一个张量也有但大小是1。

比如：`a = reshape(1,2,3)` `b=reshape(,1,3)`，这两个可以相加；`a=reshape(1,2,3)` `b=reshape(,1,2)`，这两个不可以，因为最右侧的数字不相同，且没有任意一个为`1`或者为空。

判断能不能广播：张量的维度是否相同，如果张量中某个维度不相同，是否为 1 或者为空。

## 截取
```python
X = torch.arange(12).reshape(3,4)

X[1,2] #获取第一行第二列的元素
X[1:2] #获取第一行的元素，包头不包尾
X[1:3] #获取第一行到第二行的元素
X[:,1:2] #获取第一列的元素
X[:,0:2] #获取0列到第一列的元素
```
> [!important]
> `a:b` 包头不包尾

# 数据操作
label::`sec_ndarray`

为了能够完成各种数据操作，我们需要某种方法来存储和操作数据。
通常，我们需要做两件重要的事：（1）获取数据；（2）将数据读入计算机后对其进行处理。
如果没有某种方法来存储数据，那么获取数据是没有意义的。

首先，我们介绍$n$维数组，也称为*张量*（tensor）。使用过Python中NumPy计算包的读者会对本部分很熟悉。无论使用哪个深度学习框架，它的*张量类*（在MXNet中为`ndarray`，在PyTorch和TensorFlow中为`Tensor`）都与Numpy的`ndarray`类似。但深度学习框架又比Numpy的`ndarray`多一些重要功能：首先，GPU很好地支持加速计算，而NumPy仅支持CPU计算；其次，张量类支持自动微分。这些功能使得张量类更适合深度学习。如果没有特殊说明，本书中所说的张量均指的是张量类的实例。
## 入门

本节的目标是帮助读者了解并运行一些在阅读本书的过程中会用到的基本数值计算工具。如果你很难理解一些数学概念或库函数，请不要担心。
后面的章节将通过一些实际的例子来回顾这些内容。如果你已经具有相关经验，想要深入学习数学内容，可以跳过本节。


